{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üçé Personal Wellness RAG Agent"
      ],
      "metadata": {
        "id": "PDvYpX2tw-aF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Setup and Installation\n",
        "\n",
        "Let's start by installing and importing all the libraries we'll need for our NewsBot system.\n"
      ],
      "metadata": {
        "id": "wDhzeKA4xH4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD5Z_0pPMxy0",
        "outputId": "60b36825-725d-470b-cf3f-a39938467f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.9.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0.post1)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.11/dist-packages (0.9)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.12)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.99.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community langchain_openai langgraph pypdf pydantic python-docx faiss-cpu docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.caches import InMemoryCache\n",
        "from langchain_core.globals import set_llm_cache\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from typing import List, Dict, Optional\n",
        "from pydantic import BaseModel\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "-23i_Bp2Nmfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Prompts"
      ],
      "metadata": {
        "id": "jC21OElOxzTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenerationPrompts():\n",
        "    INPUT_VALIDATION_SYSTEM = \"\"\" You are a meticulous reviewer of words and phrases. \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def input_validation_user(query: str) -> str:\n",
        "        return f\"\"\" Topic: {query}\n",
        "                Determine whether the query is inappropriate or contains harmful requests.\n",
        "\n",
        "                Only respond with True if it does or False if it doesnt\n",
        "\n",
        "                \"\"\"\n",
        "\n",
        "    BIODATA_SYNOPSIS_SYSTEM = \"\"\" You are a health specialist. Extract important information that\n",
        "                               could be used to provide valuable advice about user issues.\n",
        "                               \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def biodata_synopsis_user(heart_rate: str, mood: str, did_exercise: str, sleep_description: str, docs: Dict[str, List[Document]]) -> str:\n",
        "        return f\"\"\" User Biometric Data:\n",
        "                - Heart rate: {heart_rate}\n",
        "                - Heart rate content: {docs[\"heart_rate\"]}\n",
        "\n",
        "                - Mood: {mood}\n",
        "                - Mood content: {docs[\"mood\"]}\n",
        "\n",
        "                - Did user exercise today?: {did_exercise}\n",
        "                - Exercise content: {docs[\"did_exercise\"]}\n",
        "\n",
        "                - How user slept: {sleep_description}\n",
        "                - Sleep content: {docs[\"sleep_description\"]}\n",
        "\n",
        "                Using the above user biometrics and their respective content provide a brief synopsis of the users health.\n",
        "                Provide either motivation or concern depending on users biometric data and add any information from the content\n",
        "                data that might be valuable to the user.\n",
        "\n",
        "                \"\"\"\n",
        "\n",
        "    ADVICE_GENERATION_SYSTEM = \"\"\" You are a medical professional providing motivational or concerned advice on patient health\n",
        "                               data and queries.\n",
        "                               \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def advice_generation_user(query_docs: List[Document], query: str, synopsis: str) -> str:\n",
        "        return f\"\"\"Query: {query}\n",
        "                Content: {query_docs}\n",
        "\n",
        "                If there is a positive affirmation in the content add it here. Only add the phrase.\n",
        "                if there are breathing exercises in the content choose one at random and add it here. Should be in a numbered step by step list.\n",
        "\n",
        "                if the content is not about positive affirmations provide numbered snippets containing some professional wellness advice to answer the users query.\n",
        "\n",
        "                Synopsis: {synopsis}\n",
        "\n",
        "                Next provide a summary based on the users synopsis\n",
        "                \"\"\""
      ],
      "metadata": {
        "id": "k2nGatDeOLTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create State"
      ],
      "metadata": {
        "id": "pN6u3KlQx3FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create User State\n",
        "class UserState(BaseModel):\n",
        "    query: str\n",
        "    heart_rate: str\n",
        "    mood: str\n",
        "    did_exercise: str\n",
        "    sleep_description: str\n",
        "    synopsis: Optional[str] = None\n",
        "    retrieved_docs: Optional[List[Document]] = None\n",
        "    docs_dict: Optional[Dict[str, List[Document]]] = None\n",
        "    advice: Optional[str] = None"
      ],
      "metadata": {
        "id": "z8a_LciQOaOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Workflow"
      ],
      "metadata": {
        "id": "Z-CR2f4gx72k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Workflow:\n",
        "    def __init__(self):\n",
        "        self.llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
        "        self.prompts = GenerationPrompts()\n",
        "        self.workflow = self._build_workflow()\n",
        "        self.cache = InMemoryCache()\n",
        "        set_llm_cache(self.cache)\n",
        "\n",
        "    # Create LangGraph workflow\n",
        "    def _build_workflow(self):\n",
        "        graph = StateGraph(UserState)\n",
        "        graph.add_node(\"check_input\", self.input_validation)\n",
        "        graph.add_node(\"load_add_docs\", self.load_add_documents)\n",
        "        graph.add_node(\"get_synopsis\", self.get_bio_synopsis)\n",
        "        graph.add_node(\"get_advice\", self.generate_advice)\n",
        "        graph.add_edge(START, \"load_add_docs\")\n",
        "        graph.add_conditional_edges(\"load_add_docs\", self.input_validation)\n",
        "        graph.add_edge(\"get_synopsis\", \"get_advice\")\n",
        "        graph.add_edge(\"get_advice\", END)\n",
        "        return graph.compile()\n",
        "\n",
        "    # Check input for inappropriate or harmful requests\n",
        "    def input_validation(self, state: UserState):\n",
        "        \"\"\"\n",
        "        Check the user's query for inappropriate or harmful content\n",
        "\n",
        "        Args:\n",
        "            state: The agent's saved information.\n",
        "\n",
        "        Returns:\n",
        "            String: The next node the agent should use.\n",
        "        \"\"\"\n",
        "        print(\"\\n\")\n",
        "        print(\"Checking input for inappropriate or harmful requests...\\n\")\n",
        "        messages = [\n",
        "            SystemMessage(content=self.prompts.INPUT_VALIDATION_SYSTEM),\n",
        "            HumanMessage(content=self.prompts.input_validation_user(state.query))\n",
        "        ]\n",
        "        response = self.llm.invoke(messages)\n",
        "\n",
        "        # Check if the LLM considers the query to have inappropriate or harmful requests\n",
        "        if response.content == \"True\":\n",
        "            print(\"This prompt is innappropriate or contains a harmful request.\")\n",
        "            return \"END\"\n",
        "        return \"get_synopsis\"\n",
        "\n",
        "    # Load documents (pdf, docx, doc), preprocess, and add to vector store\n",
        "    def load_add_documents(self, state: UserState):\n",
        "        \"\"\"\n",
        "        Load documents (pdf, docx, doc), preprocess, and add to vector store\n",
        "\n",
        "        Args:\n",
        "            state: The agent's saved information.\n",
        "\n",
        "        Returns:\n",
        "            Object: Documents retrieved from the vector store.\n",
        "        \"\"\"\n",
        "        docs = []\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "\n",
        "        # load documents\n",
        "        print(\"\\n\")\n",
        "        print(\"Loading Documents...\")\n",
        "        for file_path in Path(\"/content/drive/MyDrive/RAG_Documents\").iterdir():\n",
        "          print(f\"\\tFolder: {file_path}\")\n",
        "          for file_path_next in Path(file_path).iterdir():\n",
        "              print(f\"\\t\\tLoading: {file_path_next}\")\n",
        "              if file_path_next.suffix.lower() == \".pdf\":\n",
        "                  loader = PyPDFLoader(str(file_path_next))\n",
        "                  docs.extend(loader.load())\n",
        "              elif file_path_next.suffix.lower() == \".docx\":\n",
        "                  loader = Docx2txtLoader(str(file_path_next))\n",
        "                  docs.extend(loader.load())\n",
        "\n",
        "        # split documents into chunks\n",
        "        print(\"\\n\")\n",
        "        print(f\"Total Documents Loaded: {len(docs)}\")\n",
        "        print(\"Processing Documents...\")\n",
        "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "        chunks = splitter.split_documents(docs)\n",
        "        print(f\"\\nTotal Chunks: {len(chunks)}\")\n",
        "\n",
        "        # embed documents then add them to the vector store\n",
        "        print(\"Creating Embeddings...\")\n",
        "        print(\"Adding Documents to Vector Store...\")\n",
        "        vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "        # user biometrics\n",
        "        user_biometrics = [(\"heart_rate\", state.heart_rate), (\"mood\", state.mood), (\"did_exercise\", state.did_exercise), (\"sleep_description\", state.sleep_description)]\n",
        "\n",
        "        userdata_docs = {}\n",
        "\n",
        "        retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})\n",
        "\n",
        "        # query based on user biometrics\n",
        "        for data in user_biometrics:\n",
        "            if data[0] == \"heart_rate\":\n",
        "                retrieved_docs = retriever.invoke(f\"my heart rate is {data[1]}\")\n",
        "                userdata_docs[\"heart_rate\"] = retrieved_docs\n",
        "            elif data[0] == \"mood\":\n",
        "                retrieved_docs = retriever.invoke(f\"I am {data[1]} today\")\n",
        "                userdata_docs[\"mood\"] = retrieved_docs\n",
        "            elif data[0] == \"did_exercise\":\n",
        "                retrieved_docs = retriever.invoke(f\"benefits of exercise\")\n",
        "                userdata_docs[\"did_exercise\"] = retrieved_docs\n",
        "            elif data[0] == \"sleep_description\":\n",
        "                retrieved_docs = retriever.invoke(data[1])\n",
        "                userdata_docs[\"sleep_description\"] = retrieved_docs\n",
        "\n",
        "        # make sure to get breathing exercises\n",
        "        print(\"Retrieving Queried Documents...\\n\")\n",
        "        if \"stress\" in state.query:\n",
        "          retrieved_docs_1 = retriever.invoke(\"breathing exercises\")\n",
        "        elif \"breathing\" in state.query:\n",
        "          retrieved_docs_1 = retriever.invoke(\"breathing exercises\")\n",
        "        elif \"anxiety\" in state.query:\n",
        "          retrieved_docs_1 = retriever.invoke(\"breathing exercises\")\n",
        "        else:\n",
        "          retrieved_docs = retriever.invoke(state.query)\n",
        "\n",
        "        userdata_docs[\"query\"] = retrieved_docs\n",
        "\n",
        "        return {\"retrieved_docs\": retrieved_docs, \"docs_dict\": userdata_docs}\n",
        "\n",
        "    # Get a structured synopsis from llm\n",
        "    def get_bio_synopsis(self, state: UserState):\n",
        "        \"\"\"\n",
        "        Get a structured synopsis from llm using content retrieved from the user's biometrics\n",
        "\n",
        "        Args:\n",
        "            state: The agent's saved information.\n",
        "\n",
        "        Returns:\n",
        "            String: LLM generated response.\n",
        "        \"\"\"\n",
        "        bio_docs = state.docs_dict\n",
        "\n",
        "        messages = [\n",
        "            SystemMessage(content=self.prompts.BIODATA_SYNOPSIS_SYSTEM),\n",
        "            HumanMessage(content=self.prompts.biodata_synopsis_user(state.heart_rate, state.mood, state.did_exercise, state.sleep_description, bio_docs))\n",
        "        ]\n",
        "\n",
        "        # get llm response\n",
        "        response = self.llm.invoke(messages)\n",
        "        # show bio response\n",
        "        print(f\"\\nBio Synopsis:\\n{response.content}\\n\")\n",
        "        return {\"synopsis\": response.content}\n",
        "\n",
        "    def generate_advice(self, state: UserState):\n",
        "        \"\"\"\n",
        "        Get structured advice response from llm using content retrieved from the user's query and the user's synopsis\n",
        "\n",
        "        Args:\n",
        "            state: The agent's saved information.\n",
        "\n",
        "        Returns:\n",
        "            String: LLM generated response.\n",
        "        \"\"\"\n",
        "\n",
        "        messages = [\n",
        "            SystemMessage(content=self.prompts.ADVICE_GENERATION_SYSTEM),\n",
        "            HumanMessage(content=self.prompts.advice_generation_user(state.retrieved_docs, state.query, state.synopsis))\n",
        "        ]\n",
        "\n",
        "        # get llm response\n",
        "        response = self.llm.invoke(messages)\n",
        "        return {\"advice\": response.content}\n",
        "\n",
        "\n",
        "\n",
        "    def run(self, query: str, heart_rate: str, mood: str, did_exercise: str, sleep_description: str) -> UserState:\n",
        "        \"\"\"\n",
        "        Run the agent\n",
        "\n",
        "        Args:\n",
        "            topic: The users query to be searched.\n",
        "\n",
        "        Returns:\n",
        "            Object: The final agent state\n",
        "        \"\"\"\n",
        "        starting_state = UserState(query=query, heart_rate=heart_rate, mood=mood, did_exercise=did_exercise, sleep_description=sleep_description)\n",
        "        finished_state = self.workflow.invoke(starting_state)\n",
        "        return UserState(**finished_state)"
      ],
      "metadata": {
        "id": "OorF2YUFOciD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Program"
      ],
      "metadata": {
        "id": "p_kae4pcyBFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    workflow = Workflow()\n",
        "    print(\"Personal Wellness Agent\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nWhat can I help you with?: \")\n",
        "\n",
        "        # Check if the user wants to quit the agent or make another query\n",
        "        if query.lower() in {\"quit\", \"exit\"}:\n",
        "            break\n",
        "\n",
        "        print(\"\\nüîç Ok, lets get some Biometric data first: \")\n",
        "\n",
        "        # Get user biometrics\n",
        "        heart_rate = input(\"\\n\\t What is your current heartrate?: \")\n",
        "        mood = input(\"\\t What is your current mood. (Happy, Sad, Depressed): \")\n",
        "        did_exercise = input(\"\\t Did you exercise today? (Yes, No): \")\n",
        "        sleep_description = input(\"\\t How did you sleep last night?: \")\n",
        "\n",
        "        print(\"\\n\\nAwesome, thank you for that information!\\n\\n\")\n",
        "\n",
        "        # If there is a query run the agent\n",
        "        if query:\n",
        "            result = workflow.run(query, heart_rate, mood, did_exercise, sleep_description)\n",
        "            print(f\"\\nLets see if I can help you out...\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            # Print final report\n",
        "            if result.advice:\n",
        "                print(\"My advice: \")\n",
        "                print(\"-\" * 40)\n",
        "                print(f\"{result.advice}\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSibtt-_Ope9",
        "outputId": "49feb14e-02e2-471e-fc89-1be1f02bb7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Personal Wellness Agent\n",
            "\n",
            "What can I help you with?: stress break\n",
            "\n",
            "üîç Ok, lets get some Biometric data first: \n",
            "\n",
            "\t What is your current heartrate?: 85\n",
            "\t What is your current mood. (Happy, Sad, Depressed): Sad\n",
            "\t Did you exercise today? (Yes, No): No\n",
            "\t How did you sleep last night?: I didn't sleep good\n",
            "\n",
            "\n",
            "Awesome, thank you for that information!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Loading Documents...\n",
            "\tFolder: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations/Motivation_Affirmations_Self_Determination.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations/Affirmations .docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations/Motivation_Affimrations_PODCAST_How to feel hopeful.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations/Motivation_Affirmations_Being More Optimistic Could Add Years to Your Life.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations/Motiovation_Affirmations_MH Mastermind Week 2 - Self-Talk.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3985613189.py:49: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations/Motivation_Affirmations_How to Create the Right Environment for Students to Develop a Growth Mindset.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations/Motivation_affirmations_How Gratitude Makes You Happier.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Motivation & affirmations/Positive_Affirmations.gdoc\n",
            "\tFolder: /content/drive/MyDrive/RAG_Documents/Wellness Agent Data_General_Knowledge_base\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Wellness Agent Data_General_Knowledge_base/Wellness Agent Data Acquisition_.docx\n",
            "\tFolder: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/Sleep issues & remedies_Sleep_Hygiene.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/Sleep issues & remedies_Cant sleep_what to do.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/Sleep issues & remedies_About Sleep.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/How to fall asleep fast.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/Sleep issues & remedies_Healthy-Sleep-Healthy-Brain-508.pdf\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/Sleep issues & remedies_Mastering Sleep Hygiene.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/Sleep issues & remedies_Tips for beating anxiety to get a better night.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/Sleep issues & remedies_Harvard‚ÄØHealth ‚Äú8 secrets to a good night‚Äôs sleep‚Äù¬†.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Sleep issues & remedies/Sleep issues & remedies_Cognitive.docx\n",
            "\tFolder: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common sickness & remedies_Sore throat.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common  sickenss & remedies_Back exercises in 15 minutes a day.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Exercise .docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Flu.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common sicknesses & remedies_Cold.pdf\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common sickness & remedies_Motion_Sickness.pdf\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common sickness & remedies_Headache.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common sicknesses & remedies_Cold2.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common sickness & remedies_Indigestion.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common sickenss & remedies_Dyspepsia.pdf\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Common sicknesses & remedies/Common sicknesses & remedies_Cold_Adinfo.pdf\n",
            "\tFolder: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Mental health & coping_Coping With Traumatic Events.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Depression .docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Mental‚Äëhealth problems & coping_Depression.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Mental health & coping_anxiety.pdf\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Mental health & coping_For People with Mental Health Problems.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Mental‚Äëhealth problems & coping_NCBI Bookshelf ‚ÄúCoping Mechanisms‚Äù .docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Mental health & coping_MH Mastermind Week 2 - Self-Talk.pdf\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Mental health & coping_Caring for Your Mental Health.docx\n",
            "\t\tLoading: /content/drive/MyDrive/RAG_Documents/Mental-health problems & coping/Mental_Health_Problems_coping_doing-what-matters-in-times-of-stress-eng.pdf\n",
            "\n",
            "\n",
            "Total Documents Loaded: 185\n",
            "Processing Documents...\n",
            "\n",
            "Total Chunks: 1537\n",
            "Creating Embeddings...\n",
            "Adding Documents to Vector Store...\n",
            "Retrieving Queried Documents...\n",
            "\n",
            "\n",
            "\n",
            "Checking input for inappropriate or harmful requests...\n",
            "\n",
            "\n",
            "Bio Synopsis:\n",
            "Based on the user's biometric data and content, here's a brief synopsis of their health:\n",
            "\n",
            "1. **Heart Rate**: The user's heart rate is 85 bpm, which is within the normal range for adults (60-100 bpm). However, the content suggests that relaxation techniques, such as biofeedback, can help in maintaining a steady heart rhythm and may be beneficial for overall heart health.\n",
            "\n",
            "2. **Mood**: The user is experiencing sadness. The content highlights the importance of being kind to oneself and suggests that acknowledging and allowing painful feelings to pass, like weather, can be helpful. Practicing grounding techniques and focusing on small acts of kindness can also improve mood.\n",
            "\n",
            "3. **Exercise**: The user did not exercise today. Regular physical activity is crucial for maintaining overall health, reducing the risk of chronic diseases, and improving mood. Starting with small, manageable exercise routines can be beneficial. The content suggests that even short bursts of activity can contribute to health improvements.\n",
            "\n",
            "4. **Sleep**: The user reported not sleeping well. Good sleep hygiene is essential for health and well-being. The content provides several tips for improving sleep, such as maintaining a consistent sleep schedule, creating a comfortable sleep environment, and avoiding large meals and electronic devices before bedtime.\n",
            "\n",
            "**Motivation**: It's important to focus on small, positive changes that can lead to significant improvements in overall health. Consider incorporating relaxation techniques, regular exercise, and good sleep hygiene into your daily routine. Remember, progress takes time, and every small step counts towards better health.\n",
            "\n",
            "**Concern**: The combination of poor sleep, lack of exercise, and a sad mood can impact overall well-being. It's crucial to address these areas to prevent potential health issues. Seeking support from a healthcare professional or counselor may also be beneficial in managing mood and improving sleep quality.\n",
            "\n",
            "\n",
            "Lets see if I can help you out...\n",
            "============================================================\n",
            "My advice: \n",
            "----------------------------------------\n",
            "### Breathing Exercise\n",
            "1. Sit or lie in a comfortable position and become aware of your breath.\n",
            "2. As you slowly breathe in, clench your fists, noticing sensations that accompany tightening your muscles.\n",
            "3. Gently exhale, relaxing your hands. Notice tension draining out of your muscles.\n",
            "4. Repeat this process, tensing as you inhale and releasing as you exhale, for muscle groups throughout your body.\n",
            "\n",
            "### Professional Wellness Advice\n",
            "1. **Heart Health**: Consider incorporating relaxation techniques such as biofeedback to help maintain a steady heart rhythm. This can be beneficial for overall heart health.\n",
            "2. **Mood Improvement**: Practice grounding techniques and focus on small acts of kindness to improve mood. Acknowledge and allow painful feelings to pass naturally.\n",
            "3. **Exercise**: Start with small, manageable exercise routines to improve mood and overall health. Even short bursts of activity can contribute to health improvements.\n",
            "4. **Sleep Hygiene**: Maintain a consistent sleep schedule, create a comfortable sleep environment, and avoid large meals and electronic devices before bedtime to improve sleep quality.\n",
            "\n",
            "### Summary\n",
            "The user's current health status indicates a normal heart rate but highlights areas for improvement in mood, exercise, and sleep. Incorporating relaxation techniques, regular physical activity, and good sleep hygiene can lead to significant health improvements. It's important to focus on small, positive changes and seek support if needed to manage mood and enhance sleep quality. Progress takes time, and every small step counts towards better health.\n",
            "\n",
            "What can I help you with?: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lbYsc9QlfI08"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}